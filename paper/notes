Talk about how k-med gives natural way of visualizing tree
  Would PCA benefit it?

Methods:
  PWGS run on twelve tumors from PCAWG, each possessing from 147 to 675 mutations
    Only SNV data used in model, not CNV
    CNV data was used, however, to exclude mutations in regions of variant copy number
      Such variations skew the mutation frequencies necessary to infer tumor populations
    2500 trees then sampled using MCMC from distribution of trees consistent with observed mutation freqs
      First came 1000 burn-in iterations
      Though each tree had associated likelihood, these were not used

  Each tree was then converted into a mutation pairs matrix
    Such a matrix consists of a four-element binary vector for mutation pair, indicating which of four possible relationships the pair adheres to
    Consequently, trees were clustered by clustering their associated mutpair matrices

  k-medioids:
    Distance metric: sum((a - b)**2)

Results:
  Number SSMs per dataset
    For methods: computationally intractable to perform clustering on larger datasets with >1000 mutations
      Memory and runtime limitations prevented running on larger sets

  Likelihood kmed & likelihood EM: in a
    Only for 7f1ca (K=2) does EM do better than KM
      This is out of 120 cases
      Neither of these values corresponds to lowest produced for this dataset -- EM prefers K=9, while KM prefers K=3
        BIC score likes K=3 for EM
    In only one case do they agree on # of clusters
      Otherwise, they're split
        In 5/12 cases, em_idx < km_idx
        In 6/12 cases, km_idx < em_idx
    But this is in contrast to the various measures of cluster quality related to unique trees per cluster (TB4)
    Why am I seeing high K values for predictive likelihood?
      Adding more clusters doesn't penalize the score, since I'm summing over all clusters for each tree, not taking their product
        Adding more clusters may help with a few weird outllying datapoints, while not hurting the rest

  BIC EM
    BIC prefers smaller clusters -- simply too many params for larger ones
      This is in direct contrast to likelihood metric
        Lhood never selects models with <5 clusters
        BIC never selects with >3
    Thus, contrary to '03 NIPS paper, BIC may be suitable measure, since it seems to penalize model compelxity rather heavily

  Unique trees kmed & unique trees EM
    kmed quality -- mean(# trees per node / # unique trees) -- is almost always worse than EM, save for two datasets
    Mean top tree iprovement:
      kmed: 0.085
      EM: 0.089

  # of clusters is too high for both KM and EM

Discussion:
  EM often likes empty clusters, in which case the cluster has low shared responsibility for lots of trees, but is never deemed the most likely cluster for any
    Consider 81a8, which prefers 10 clusters, 8 of which are empty
      This needn't always be so, however -- 7f1c has 9 clusters, none of which are empty

  Likelihood is poor means of determining success -- suggets kmed better, when in fact its performance is worse than EM

Future directions:
  Integrate BIC for kmed -- I should add my EM BIC scores now
    Is likelihood best means of choosing model? Probably not
  Move to variational Bayes
  Expand analysis to more datasets
    Ran out of memory on 36/48 of those tried
  Generate consensus trees for EM -- kmed lends itself nicely to this

Background:
  Each subpopulation within tumor has associated set of mutations, with some shared with varying set of other subpops, and others potentially unique
  By observing the frequencies of each mutation given a heterogeneous cell set taken from different subpops, one can infer that freqs with similar frequencies belong to same subpop
  In some cases, uncertainty occurs as to subpop structure, however
    Suppose three clusters of mutation frequencies observed in tumor -- 90%, 55%, 40%
      Then because sum(B, C) > A, B and C can't occur in different branches, eliminataing branched
      But if B was 45% instead, then things get messed up

      
  Important, then, is understanding variation in phylogenies amongst the thousands sampled
    Sometimes, these differences reflect uncertainty in the principal structure of the tree, as in the case of branching vs. linear
      The degree and nature of this uncertainty must be characterized and communicated to the researcher
    Other times, these differences are just model noise -- slightly different trees, different LLHs, but same essential features

Other things to do in future:
  Run on SciNet -- 256 GB RAM
  Run Stephen's code -- faster, may offer better numerical precision
  Add checks to my predicive likelihood evaluator to ensure that all all probailities in my likelihiood calcs (i.e., from the pis and the rhos) sum to 1 and are individually >0
    There may be a bug in this code
  Don't pick K using predictive likelihood
    Instead, pick K using BIC
    Still, it should be reasonably good for predicting LH of EM vs KM, once K is chosen
